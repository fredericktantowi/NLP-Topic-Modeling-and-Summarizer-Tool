{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0SzYH8ofCJ"
      },
      "source": [
        "### Load Citigroup dataset from json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OmO5wW0AofCK"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "citi_data = []\n",
        "with open('webhose_citigroup.json', 'r') as f:\n",
        "    for line in f.readlines():\n",
        "        citi_data.append(json.loads(line))\n",
        "\n",
        "citi_titles = [a['title'] for a in citi_data]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhBg3ezCofCM",
        "outputId": "1afdd4c1-66d7-493f-cb58-f38e8bb481ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: PYSPARK_PYTHON=python3\n"
          ]
        }
      ],
      "source": [
        "%env PYSPARK_PYTHON=python3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGPfGHOfofCO"
      },
      "source": [
        "### Set comes with duplicates:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPpOjDVeofCP",
        "outputId": "15687825-3396-47b3-a40d-732ef839c5b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(11358, 9277)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(citi_titles), len(set(citi_titles))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iV4UfzxofCQ"
      },
      "source": [
        "### We can use spark's MinHash over character n-grams\n",
        "#### We create a dataframe containing the title as a string in one column and a list of characters in another"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "miejxzCdsiza"
      },
      "outputs": [],
      "source": [
        "#pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8VE0dbzofCR",
        "outputId": "b863cc78-a2f8-47be-f23c-0ba8fe3e0306"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|               title|\n",
            "+--------------------+\n",
            "|Amarin (NASDAQ:AM...|\n",
            "|Amarin (NASDAQ:AM...|\n",
            "|Hess (NYSE:HES) G...|\n",
            "|Standard Chartere...|\n",
            "|Apergy Target of ...|\n",
            "|WPP (LON:WPP) Sto...|\n",
            "|XP Inc.â€™s (NYSE:X...|\n",
            "|Caci Internationa...|\n",
            "|Caci Internationa...|\n",
            "|DA Davidson Reite...|\n",
            "|State Street Corp...|\n",
            "|FY2020 EPS Estima...|\n",
            "|Zoetis Inc (NYSE:...|\n",
            "|FY2020 EPS Estima...|\n",
            "|Royal Bank of Can...|\n",
            "|FY2020 EPS Estima...|\n",
            "|State Street Corp...|\n",
            "|ST. LOUIS -- (Bus...|\n",
            "|BETHLEHEM, Pa., J...|\n",
            "|Reinsurance Group...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext()\n",
        "spark = SparkSession(sc)\n",
        "df = spark.createDataFrame([\n",
        "    (k, t, list(t)) for k, t in enumerate(citi_titles) if len(list(t)) >=3],\n",
        "    ['id', 'title', 'title_characters'])\n",
        "df.select('title').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pQJjYbjofCS"
      },
      "source": [
        "#### Now we use spark to select character n-grams (shingles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtbiXYVAofCT",
        "outputId": "0165dad0-98c9-4187-864a-f89acee18418"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|              ngrams|\n",
            "+--------------------+\n",
            "|[A m a, m a r, a ...|\n",
            "|[A m a, m a r, a ...|\n",
            "|[H e s, e s s, s ...|\n",
            "|[S t a, t a n, a ...|\n",
            "|[A p e, p e r, e ...|\n",
            "|[W P P, P P  , P ...|\n",
            "|[X P  , P   I,   ...|\n",
            "|[C a c, a c i, c ...|\n",
            "|[C a c, a c i, c ...|\n",
            "|[D A  , A   D,   ...|\n",
            "|[S t a, t a t, a ...|\n",
            "|[F Y 2, Y 2 0, 2 ...|\n",
            "|[Z o e, o e t, e ...|\n",
            "|[F Y 2, Y 2 0, 2 ...|\n",
            "|[R o y, o y a, y ...|\n",
            "|[F Y 2, Y 2 0, 2 ...|\n",
            "|[S t a, t a t, a ...|\n",
            "|[S T ., T .  , . ...|\n",
            "|[B E T, E T H, T ...|\n",
            "|[R e i, e i n, i ...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import NGram\n",
        "\n",
        "ngram = NGram(n=3, inputCol='title_characters', outputCol='ngrams')\n",
        "ngram_df = ngram.transform(df)\n",
        "ngram_df.select('ngrams').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xf4tXhXofCT"
      },
      "source": [
        "#### And transform those in-grams into binary vectors we can use in MinHash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toZENfZoofCU",
        "outputId": "4c0f8574-c61d-4f3e-81cb-1b0dd1baf81d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|              vector|\n",
            "+--------------------+\n",
            "|(12947,[0,5,6,8,9...|\n",
            "|(12947,[0,5,6,8,9...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[5,6,7,8,9...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[8,9,11,12...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[0,7,8,11,...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[1,7,9,12,...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[7,9,11,28...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[1,7,9,12,...|\n",
            "|(12947,[0,1,2,3,4...|\n",
            "|(12947,[12,17,20,...|\n",
            "|(12947,[38,292,32...|\n",
            "|(12947,[7,8,14,17...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import CountVectorizer \n",
        "\n",
        "count_vectorizer = CountVectorizer(inputCol='ngrams', outputCol='vector', binary=True)\n",
        "model = count_vectorizer.fit(ngram_df)\n",
        "cv_df = model.transform(ngram_df)\n",
        "\n",
        "# the vectors are displayed in 'sparse' format, \n",
        "# i.e. the numbers shown are the indices i of vector x where x[i]=1, \n",
        "# and x[k]=0 for all other k\n",
        "cv_df.select('vector').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0YBOA5tofCV"
      },
      "source": [
        "#### Now we can apply MinHash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7IAKU2rofCV",
        "outputId": "d0e031f5-1345-4904-c3b2-98dcf7c2bccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+\n",
            "|             minHash|\n",
            "+--------------------+\n",
            "|[[6498880.0], [95...|\n",
            "|[[6498880.0], [95...|\n",
            "|[[1.5733472E7], [...|\n",
            "|[[4.1623735E7], [...|\n",
            "|[[6.7513998E7], [...|\n",
            "|[[6333835.0], [7....|\n",
            "|[[1.5898517E7], [...|\n",
            "|[[1.3424824E7], [...|\n",
            "|[[1.3424824E7], [...|\n",
            "|[[1.3754914E7], [...|\n",
            "|[[4.6406076E7], [...|\n",
            "|[[2.2989506E7], [...|\n",
            "|[[1.5898517E7], [...|\n",
            "|[[2.2989506E7], [...|\n",
            "|[[4.1623735E7], [...|\n",
            "|[[2.2989506E7], [...|\n",
            "|[[4.6406076E7], [...|\n",
            "|[[1.8207165E7], [...|\n",
            "|[[1.14842273E8], ...|\n",
            "|[[5.3497065E7], [...|\n",
            "+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import MinHashLSH\n",
        "\n",
        "min_hash = MinHashLSH(inputCol='vector', outputCol='minHash', seed=0, numHashTables=10)\n",
        "model = min_hash.fit(cv_df)\n",
        "hash_df = model.transform(cv_df)\n",
        "\n",
        "# We now have the min hash values for the dataset of article titles\n",
        "hash_df.select('minHash').show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cF0Sq3FofCW",
        "outputId": "21039219-dec1-4131-f2ba-4df653893b15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+----------------+\n",
            "|            datasetA|            datasetB|jaccard_distance|\n",
            "+--------------------+--------------------+----------------+\n",
            "|{8602, Aston Mart...|{8602, Aston Mart...|             0.0|\n",
            "|{1167, On The Bea...|{138, On The Beac...|             0.0|\n",
            "|{7158, EVO Paymen...|{7160, EVO Paymen...|             0.0|\n",
            "|{10912, Tandem Di...|{10913, Tandem Di...|             0.0|\n",
            "|{6500, CMS Energy...|{5318, CMS Energy...|             0.0|\n",
            "|{9437, PhaseBio P...|{9464, PhaseBio P...|             0.0|\n",
            "|{4768, Facebook (...|{4768, Facebook (...|             0.0|\n",
            "|{9846, News Highl...|{9576, News Highl...|             0.0|\n",
            "|{6795, Canary Wha...|{6795, Canary Wha...|             0.0|\n",
            "|{5285, Brokerages...|{5285, Brokerages...|             0.0|\n",
            "|{2534, SYSMEX COR...|{2534, SYSMEX COR...|             0.0|\n",
            "|{3044, Bank of Am...|{2952, Bank of Am...|             0.0|\n",
            "|{10846, Royal Dut...|{10846, Royal Dut...|             0.0|\n",
            "|{7291, NVIDIA NVD...|{7291, NVIDIA NVD...|             0.0|\n",
            "|{875, NetApp (NAS...|{1332, NetApp (NA...|             0.0|\n",
            "|{5700, Wix.Com (N...|{5729, Wix.Com (N...|             0.0|\n",
            "|{6286, Saudi sove...|{6263, Saudi sove...|             0.0|\n",
            "|{1378, Marstonâ€™s ...|{1378, Marstonâ€™s ...|             0.0|\n",
            "|{1402, Marstonâ€™s ...|{1378, Marstonâ€™s ...|             0.0|\n",
            "|{804, Desjardins ...|{804, Desjardins ...|             0.0|\n",
            "+--------------------+--------------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "joined_rows = model.approxSimilarityJoin(cv_df, cv_df, threshold=0.05, distCol='jaccard_distance')\n",
        "# the returned dataframe will be pairs of rows where each pair has an estimated distance of at most the threshold\n",
        "joined_rows.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3KJxZHKofCW"
      },
      "source": [
        "#### We can now see all duplicates of a title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6AtoOOeofCW",
        "outputId": "0119457a-c782-422a-dac9-c44af9e94bb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+--------------------+\n",
            "|               title|               title|\n",
            "+--------------------+--------------------+\n",
            "|Okta (NASDAQ:OKTA...|Okta (NASDAQ:OKTA...|\n",
            "|Okta (NASDAQ:OKTA...|Okta (NASDAQ:OKTA...|\n",
            "+--------------------+--------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "joined_rows.filter(joined_rows.datasetA.id == 1561).select(col('datasetA.title'), col('datasetB.title')).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkBn975GofCX"
      },
      "source": [
        "#### And we can deduplicate the whole dataset if we want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txD6B66TofCX",
        "outputId": "30a316dd-616f-4088-b943-ea4853720592"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+----------------------+\n",
            "|               title|min(datasetA.id AS id)|\n",
            "+--------------------+----------------------+\n",
            "|Hoertkorn Richard...|                 10066|\n",
            "|AMC Entertainment...|                  1253|\n",
            "|Citigroup Reaffir...|                  5435|\n",
            "|ITV (LON:ITV) Sto...|                  7801|\n",
            "|Cellectisâ€™ (CLLS)...|                  9734|\n",
            "|Credit Suisse Gro...|                  3201|\n",
            "|Royal Mail (LON:R...|                  3902|\n",
            "|LYFT (NASDAQ:LYFT...|                  6689|\n",
            "|Laureate Educatio...|                 11192|\n",
            "|Marks and Spencer...|                  2986|\n",
            "|BidaskClub Upgrad...|                  2384|\n",
            "|Playa Hotels & Re...|                  7578|\n",
            "|National Bank Fin...|                   749|\n",
            "|Avalara (NYSE:AVL...|                  8328|\n",
            "|Welbilt, Inc to P...|                  9904|\n",
            "|Green Dot (NYSE:G...|                  3808|\n",
            "|Brokerages Set Da...|                  8665|\n",
            "|Xilinx (NASDAQ:XL...|                  8327|\n",
            "|Warrior Met Coal ...|                 10953|\n",
            "|Zacks Investment ...|                  1182|\n",
            "+--------------------+----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# this will return the first id for each title in the dataset\n",
        "deduplicated_df = joined_rows.groupby(col('datasetA.title')).min('datasetA.id')\n",
        "deduplicated_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBxVgpUMofCY",
        "outputId": "f48f392a-e1f8-43fa-8e4b-57630a209fdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of duplicates (MinHash): 2081\n",
            "Number of deduplicates (MinHash): 9277\n"
          ]
        }
      ],
      "source": [
        "deduplicated_titles = deduplicated_df.toPandas()\n",
        "deduplicated_titles = deduplicated_titles.rename(columns = {'min(datasetA.id AS id)':'index'})\n",
        "\n",
        "print(\"Number of duplicates (MinHash): \" + str(len(citi_titles)-len(deduplicated_titles)))\n",
        "print(\"Number of deduplicates (MinHash): \" + str(len(deduplicated_titles)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZB3KbEXE9fHb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_citi_newsfeeds = pd.read_json(\"webhose_citigroup.json\", lines=True)\n",
        "df_citi_newsfeeds.reset_index(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JbQ0rogc-yD3"
      },
      "outputs": [],
      "source": [
        "new_citi_news_df = deduplicated_titles.merge(df_citi_newsfeeds, on='index', how='left')\n",
        "new_citi_news_df.drop(['title_x', 'index'], axis=1, inplace=True)\n",
        "new_citi_news_df.to_json('deduplicated_newsfeeds.json', orient = 'split', compression = 'infer', index = 'true')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "APAN5430_Final_project_Deduplication.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
